{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongpingping/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (1,2,8,9,14,25,131,132,133,161,162) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38636, 33)\n",
      "SID                    0\n",
      "ISO_TIME               0\n",
      "LON                    0\n",
      "LAT                    0\n",
      "STORM_SPEED            0\n",
      "DIST2LAND              0\n",
      "TRACK_TYPE             0\n",
      "STORM_DIR              0\n",
      "NATURE                 0\n",
      "SUBBASIN               0\n",
      "BASIN                  0\n",
      "LANDFALL             552\n",
      "USA_WIND            6669\n",
      "TOKYO_R30_DIR       7698\n",
      "TOKYO_GRADE         7698\n",
      "TOKYO_R50_DIR       7698\n",
      "TOKYO_PRES          7784\n",
      "USA_POCI           13524\n",
      "USA_ROCI           13577\n",
      "USA_RMW            13612\n",
      "TOKYO_R30_LONG     19644\n",
      "TOKYO_R30_SHORT    19650\n",
      "USA_R34_NE         21009\n",
      "USA_R34_SE         21065\n",
      "USA_R34_NW         21077\n",
      "USA_R34_SW         21180\n",
      "TOKYO_LAND         21498\n",
      "TOKYO_R50_LONG     28192\n",
      "TOKYO_R50_SHORT    28208\n",
      "USA_R50_NE         29474\n",
      "USA_R50_SE         29486\n",
      "USA_R50_NW         29514\n",
      "USA_R50_SW         29526\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "# 显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# 设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth', 100)\n",
    "file = '../../dataset/ibtracs.WP.list.v04r00.csv'\n",
    "\n",
    "data = pd.read_csv(file)\n",
    "\n",
    "# data = data[['SID', 'BASIN', 'SUBBASIN', 'ISO_TIME','NATURE', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'WMO_AGENCY', 'DIST2LAND', 'LANDFALL',\n",
    "#               'USA_AGENCY','USA_R34_NE','USA_R34_SE',\"USA_R34_SW\",'USA_R34_NW','USA_R50_NE','USA_R50_SE','USA_R50_SW','USA_R50_NW',\n",
    "#              'USA_POCI','USA_ROCI','USA_RMW','USA_EYE','TOKYO_R50_DIR','TOKYO_R50_LONG','TOKYO_R50_SHORT','TOKYO_R30_DIR',\n",
    "#              'TOKYO_R30_LONG','TOKYO_R30_SHORT','TOKYO_LAND','STORM_SPEED','STORM_DIR'\n",
    "# ]]\n",
    "# data = data[['SID', 'ISO_TIME','LON', 'LAT','STORM_SPEED', 'DIST2LAND', 'TRACK_TYPE', \n",
    "#        'STORM_DIR',   'NATURE', 'SUBBASIN',\n",
    "#        'BASIN', 'LANDFALL', 'USA_SSHS', 'USA_ATCF_ID','USA_WIND', 'TOKYO_R30_DIR', 'TOKYO_GRADE', 'TOKYO_R50_DIR',\n",
    "#        'TOKYO_PRES',  'USA_STATUS', 'CMA_CAT',\n",
    "#        'USA_PRES',  'CMA_PRES', 'CMA_WIND', 'USA_POCI',\n",
    "#        'USA_ROCI', 'USA_RMW', 'HKO_CAT', 'HKO_WIND', 'HKO_PRES',\n",
    "#         'TOKYO_R30_LONG', 'TOKYO_WIND', 'TOKYO_R30_SHORT',\n",
    "#        'USA_R34_NE', 'USA_R34_SE', 'USA_R34_NW', 'USA_R34_SW', 'TOKYO_LAND',\n",
    "#        'WMO_AGENCY', 'WMO_PRES', 'USA_AGENCY', 'WMO_WIND', 'TOKYO_R50_LONG',\n",
    "#        'TOKYO_R50_SHORT', 'USA_R50_NE', 'USA_R50_SE', 'USA_R50_NW',\n",
    "#        'USA_R50_SW']]\n",
    "data = data[['SID', 'ISO_TIME','LON', 'LAT','STORM_SPEED', 'DIST2LAND', 'TRACK_TYPE', 'STORM_DIR', 'NATURE', 'SUBBASIN','BASIN', 'LANDFALL', 'USA_WIND', 'TOKYO_R30_DIR', 'TOKYO_GRADE', 'TOKYO_R50_DIR','TOKYO_PRES', 'USA_POCI','USA_ROCI', 'USA_RMW', 'TOKYO_R30_LONG', \n",
    "             'TOKYO_R30_SHORT', 'USA_R34_NE', 'USA_R34_SE', 'USA_R34_NW', 'USA_R34_SW', 'TOKYO_LAND',  'TOKYO_R50_LONG', 'TOKYO_R50_SHORT', 'USA_R50_NE', 'USA_R50_SE', 'USA_R50_NW','USA_R50_SW']]\n",
    "data = data[1:]\n",
    "data['ISO_TIME'] =  pd.to_datetime(data['ISO_TIME'])\n",
    "begin = datetime.datetime(2000,1,1,0,0,0)\n",
    "# 选择西北太平洋 且2000年之后的数据\n",
    "data = data[(data['BASIN']=='WP') & (data['ISO_TIME']>=begin)]\n",
    "dataNew = data.replace({' ':np.nan})\n",
    "dataNew.to_csv('original_data.csv')\n",
    "print(dataNew.shape)\n",
    "missing = dataNew.isnull().sum()\n",
    "print(missing)\n",
    "\n",
    "#缺失值的展示 \n",
    "def plot_missing(df):\n",
    "    # 对缺失值列进行计数\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    #missing.sort_values(inplace=True)\n",
    "    missing.plot.bar(figsize=(12,6))\n",
    "    missing.sort_values(inplace=True)\n",
    "#     msno.matrix(df,)\n",
    "    plt.savefig('missing.png')\n",
    "plot_missing(dataNew)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码后维度 (38636, 42)\n",
      "42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>ISO_TIME</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>DIST2LAND</th>\n",
       "      <th>STORM_DIR</th>\n",
       "      <th>LANDFALL</th>\n",
       "      <th>USA_WIND</th>\n",
       "      <th>TOKYO_R30_DIR</th>\n",
       "      <th>TOKYO_GRADE</th>\n",
       "      <th>TOKYO_R50_DIR</th>\n",
       "      <th>TOKYO_PRES</th>\n",
       "      <th>USA_POCI</th>\n",
       "      <th>USA_ROCI</th>\n",
       "      <th>USA_RMW</th>\n",
       "      <th>TOKYO_R30_LONG</th>\n",
       "      <th>TOKYO_R30_SHORT</th>\n",
       "      <th>USA_R34_NE</th>\n",
       "      <th>USA_R34_SE</th>\n",
       "      <th>USA_R34_NW</th>\n",
       "      <th>USA_R34_SW</th>\n",
       "      <th>TOKYO_LAND</th>\n",
       "      <th>TOKYO_R50_LONG</th>\n",
       "      <th>TOKYO_R50_SHORT</th>\n",
       "      <th>USA_R50_NE</th>\n",
       "      <th>USA_R50_SE</th>\n",
       "      <th>USA_R50_NW</th>\n",
       "      <th>USA_R50_SW</th>\n",
       "      <th>NATURE_DS</th>\n",
       "      <th>NATURE_ET</th>\n",
       "      <th>NATURE_MX</th>\n",
       "      <th>NATURE_NR</th>\n",
       "      <th>NATURE_SS</th>\n",
       "      <th>NATURE_TS</th>\n",
       "      <th>SUBBASIN_MM</th>\n",
       "      <th>BASIN_WP</th>\n",
       "      <th>TRACK_TYPE_PROVISIONAL</th>\n",
       "      <th>TRACK_TYPE_main</th>\n",
       "      <th>TRACK_TYPE_spur-merge</th>\n",
       "      <th>TRACK_TYPE_spur-other</th>\n",
       "      <th>TRACK_TYPE_spur-split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000125N06136</td>\n",
       "      <td>2000-05-03 18:00:00</td>\n",
       "      <td>0.446468</td>\n",
       "      <td>0.0910569</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.243235</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.243541</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000125N06136</td>\n",
       "      <td>2000-05-03 21:00:00</td>\n",
       "      <td>0.444404</td>\n",
       "      <td>0.100366</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.264317</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.26465</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000125N06136</td>\n",
       "      <td>2000-05-04 00:00:00</td>\n",
       "      <td>0.442716</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.281938</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.282294</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000125N06136</td>\n",
       "      <td>2000-05-04 03:00:00</td>\n",
       "      <td>0.441715</td>\n",
       "      <td>0.116179</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.29421</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>0.294581</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000125N06136</td>\n",
       "      <td>2000-05-04 06:00:00</td>\n",
       "      <td>0.441465</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.0689655</td>\n",
       "      <td>0.302077</td>\n",
       "      <td>0.00555556</td>\n",
       "      <td>0.302457</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SID             ISO_TIME       LON        LAT STORM_SPEED  \\\n",
       "0  2000125N06136  2000-05-03 18:00:00  0.446468  0.0910569    0.137931   \n",
       "1  2000125N06136  2000-05-03 21:00:00  0.444404   0.100366    0.126437   \n",
       "2  2000125N06136  2000-05-04 00:00:00  0.442716   0.108943    0.114943   \n",
       "3  2000125N06136  2000-05-04 03:00:00  0.441715   0.116179    0.091954   \n",
       "4  2000125N06136  2000-05-04 06:00:00  0.441465   0.121951   0.0689655   \n",
       "\n",
       "  DIST2LAND   STORM_DIR  LANDFALL USA_WIND TOKYO_R30_DIR TOKYO_GRADE  \\\n",
       "0  0.243235    0.955556  0.243541  0.09375           NaN         NaN   \n",
       "1  0.264317    0.958333   0.26465  0.09375           NaN         NaN   \n",
       "2  0.281938    0.966667  0.282294  0.09375           NaN         NaN   \n",
       "3   0.29421    0.980556  0.294581  0.09375           NaN         NaN   \n",
       "4  0.302077  0.00555556  0.302457  0.09375           NaN         NaN   \n",
       "\n",
       "  TOKYO_R50_DIR TOKYO_PRES USA_POCI USA_ROCI USA_RMW TOKYO_R30_LONG  \\\n",
       "0           NaN        NaN      NaN      NaN     NaN            NaN   \n",
       "1           NaN        NaN      NaN      NaN     NaN            NaN   \n",
       "2           NaN        NaN      NaN      NaN     NaN            NaN   \n",
       "3           NaN        NaN      NaN      NaN     NaN            NaN   \n",
       "4           NaN        NaN      NaN      NaN     NaN            NaN   \n",
       "\n",
       "  TOKYO_R30_SHORT USA_R34_NE USA_R34_SE USA_R34_NW USA_R34_SW TOKYO_LAND  \\\n",
       "0             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  TOKYO_R50_LONG TOKYO_R50_SHORT USA_R50_NE USA_R50_SE USA_R50_NW USA_R50_SW  \\\n",
       "0            NaN             NaN        NaN        NaN        NaN        NaN   \n",
       "1            NaN             NaN        NaN        NaN        NaN        NaN   \n",
       "2            NaN             NaN        NaN        NaN        NaN        NaN   \n",
       "3            NaN             NaN        NaN        NaN        NaN        NaN   \n",
       "4            NaN             NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  NATURE_DS NATURE_ET NATURE_MX NATURE_NR NATURE_SS NATURE_TS SUBBASIN_MM  \\\n",
       "0         0         0         0         0         0         1           0   \n",
       "1         0         0         0         0         0         1           0   \n",
       "2         0         0         0         0         0         1           0   \n",
       "3         0         0         0         0         0         1           0   \n",
       "4         0         0         0         0         0         1           0   \n",
       "\n",
       "  BASIN_WP TRACK_TYPE_PROVISIONAL TRACK_TYPE_main TRACK_TYPE_spur-merge  \\\n",
       "0        0                      0               1                     0   \n",
       "1        0                      0               1                     0   \n",
       "2        0                      0               1                     0   \n",
       "3        0                      0               1                     0   \n",
       "4        0                      0               1                     0   \n",
       "\n",
       "  TRACK_TYPE_spur-other TRACK_TYPE_spur-split  \n",
       "0                     0                     0  \n",
       "1                     0                     0  \n",
       "2                     0                     0  \n",
       "3                     0                     0  \n",
       "4                     0                     0  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据预处理\n",
    "# one-hot 编码\n",
    "# 归一化特征 TRACK_TYPE, NATURE,SUBBASIN,BASIN,HKO_CAT\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    " \n",
    "class One_hot_encoder:\n",
    "    def __init__(self, df, column_name_list):\n",
    "        self.df = df\n",
    "        self.column_name_list = column_name_list\n",
    "\n",
    "    def multi_column_encoder(self):\n",
    "        Enc_ohe, Enc_label = OneHotEncoder(), LabelEncoder()\n",
    "        for column_name in self.column_name_list:\n",
    "            self.df[\"Dummies\"] = Enc_label.fit_transform(self.df[column_name])\n",
    "            self.df_dummies = pd.DataFrame(Enc_ohe.fit_transform(self.df[[\"Dummies\"]]).todense(),\n",
    "                                           columns=Enc_label.classes_)\n",
    "            self.df_dummies.rename(columns=lambda x: column_name + \"_\" + x, inplace=True)\n",
    "            self.df = pd.concat([self.df, self.df_dummies], axis=1)\n",
    "            self.df.drop([\"Dummies\"], axis=1, inplace=True)\n",
    "        self.df.drop(self.column_name_list, axis=1, inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    \n",
    "column_name_list = ['NATURE', 'SUBBASIN', 'BASIN','TRACK_TYPE']\n",
    "dataNew = pd.read_csv('original_data.csv')\n",
    "dataNew.drop(['DEL'],axis = 1,inplace=True)\n",
    "\n",
    "df_encoded = One_hot_encoder(dataNew, column_name_list).multi_column_encoder()\n",
    "pd.set_option('display.max_columns', None)\n",
    "# 编码后维度\n",
    "print('编码后维度',df_encoded.shape)\n",
    "# df_encoded.head()\n",
    "\n",
    "# # 归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "minMaxScaler = MinMaxScaler()\n",
    "data_str = df_encoded[['SID','ISO_TIME']]\n",
    "data_num = df_encoded.iloc[:,2:]\n",
    "num_columns = data_num.columns\n",
    "col = ['SID','ISO_TIME']\n",
    "col += list(num_columns)\n",
    "print(len(col))\n",
    "data_v = data_num.values.astype(np.float)\n",
    "data_v = minMaxScaler.fit_transform(data_v)\n",
    "data_v = np.hstack((data_str.values,data_v))\n",
    "data = pd.DataFrame(data_v,columns=col)\n",
    "data.to_csv('data_norm.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 epoch:1,loss:0.8123567700386047\n",
      "测试集 epoch:1,loss is 0.9591184854507446\n",
      "训练集 epoch:2,loss:0.04426104202866554\n",
      "测试集 epoch:2,loss is 0.04125341400504112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9b40cc3777e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0moptimizier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mhidden_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/study/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9b40cc3777e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m                                     )\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/study/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/study/venv/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/study/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/study/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/study/venv/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练啦\n",
    "import torch\n",
    "import time\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt# 数据加载\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class DataSet(Dataset):\n",
    "    '''\n",
    "    构建数据集\n",
    "    '''\n",
    "    def __init__(self,data_pd):\n",
    "        data_DAE = np.array(data_pd)\n",
    "        self.x_data = torch.from_numpy(data_DAE[:,:]).type(torch.float32)\n",
    "        self.y_data = torch.from_numpy(data_DAE[:,:]).type(torch.float32)\n",
    "        self.len = data_DAE.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        返回数据的数目\n",
    "        '''\n",
    "        return self.len\n",
    "    \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# 训练模型啦！\n",
    "class Auto_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Auto_Encoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(nn.Dropout(p=0.5),\n",
    "                                     nn.Linear(40,32),\n",
    "                                    nn.ReLU(True),\n",
    "                                     nn.Dropout(p=0.5),\n",
    "                                    nn.Linear(32,16),\n",
    "                                    nn.ReLU(True),\n",
    "#                                     nn.Dropout(p=0.5),\n",
    "#                                     nn.Linear(24,16),\n",
    "#                                     nn.ReLU(True),\n",
    "                                     \n",
    "                                     nn.Dropout(p=0.5),\n",
    "                                      nn.Linear(16,8),\n",
    "                                    nn.ReLU(True),\n",
    "                                     nn.Dropout(p=0.5),\n",
    "                                     nn.Linear(8,4)\n",
    "                                     \n",
    "                                    )\n",
    "        self.decoder = nn.Sequential( nn.Dropout(p=0.5),\n",
    "                                     nn.Linear(4,8),\n",
    "                                    nn.ReLU(True),\n",
    "                                     nn.Dropout(p=0.5),\n",
    "                                    nn.Linear(8,16),\n",
    "                                    nn.ReLU(True),\n",
    "#                                      nn.Dropout(p=0.5),\n",
    "#                                      nn.Linear(16,24),\n",
    "#                                      nn.ReLU(True),\n",
    "                                     nn.Dropout(p=0.5),\n",
    "                                     nn.Linear(16,32),\n",
    "                                     nn.ReLU(True),\n",
    "                                     nn.Dropout(p=0.5),\n",
    "                                     nn.Linear(32,40),\n",
    "                                     nn.Tanh()\n",
    "#                                      nn.Sigmoid()\n",
    "                                    )\n",
    "    def forward(self,x):\n",
    "        encoder = self.encoder(x)\n",
    "        decoder = self.decoder(encoder)\n",
    "        return encoder,decoder\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 画图用曲线\n",
    "    start = time.time()\n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "    x_epoch = []\n",
    "    batch_size = 64\n",
    "    lr = 0.001\n",
    "    # 表示L2正则化\n",
    "    weight_decay = 1e-4\n",
    "    epoches = 100\n",
    "    model = Auto_Encoder()\n",
    "#     model.apply(weights_init)\n",
    "\n",
    "# 权重初始化\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,nn.Conv2d):\n",
    "            nn.init.normal(m.weight.data)\n",
    "            nn.init.xavier_normal(m.weight.data)\n",
    "            nn.init.kaiming_normal(m.weight.data)#卷积层参数初始化\n",
    "            m.bias.data.fill_(0)\n",
    "        elif isinstance(m,nn.Linear):\n",
    "            m.weight.data.normal_()#全连接层参数初始化\n",
    "            \n",
    "    data_all = pd.read_csv('data_norm.csv')\n",
    "    data_all = data_all.replace({np.nan:0.0})\n",
    "\n",
    "#     data_all.values.replaces({np.nan:'0'})\n",
    "    # 去掉ID和时间以及序号\n",
    "    data_all = data_all.iloc[:,3:]\n",
    "    # 数据集划分 \n",
    "    data_1,data_2= train_test_split(data_all,test_size=0.2,shuffle=True)\n",
    "    \n",
    "    train_data = DataSet(data_1)\n",
    "    test_data = DataSet(data_2)\n",
    "    # dataLoader构造\n",
    "    train_loader = DataLoader(train_data,batch_size = batch_size,shuffle = True)\n",
    "    test_loader = DataLoader(test_data,batch_size=batch_size,shuffle = False)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizier = optim.Adam(model.parameters(),lr = lr,weight_decay = weight_decay)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda\n",
    "    for epoch in range(epoches):\n",
    "        train_batch_total = 0\n",
    "        test_batch_total = 0\n",
    "        test_loss = 0\n",
    "        train_loss = 0        \n",
    "#         for param_group in optimizier.param_groups:\n",
    "#             param_group['lr'] *= 0.1\n",
    "        # 训练\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            x,y = data\n",
    "            optimizier.zero_grad()\n",
    "            hidden_vector,output = model(x)\n",
    "            loss = criterion(output,y)\n",
    "            loss.backward()\n",
    "            optimizier.step()\n",
    "        print('训练集 epoch:{},loss:{}'.format(epoch+1,loss.item()))\n",
    "        loss_train.append(loss.item())\n",
    "        \n",
    "        # 测试\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx,data in enumerate(test_loader):\n",
    "                x,y = data\n",
    "                hidden_vector,output = model(x)\n",
    "                loss = criterion(output,y)\n",
    "#                 test_loss += loss.item()\n",
    "                test_batch_total += 1\n",
    "#             print('测试集 epoch:{},loss is {}'.format((epoch+1),test_loss/test_batch_total))\n",
    "            print('测试集 epoch:{},loss is {}'.format((epoch+1),loss.item()))\n",
    "            loss_test.append(loss.item())\n",
    "    \n",
    "    torch.save(model, 'AE_model.pkl')\n",
    "# 可视化\n",
    "    x_epoch = np.arange(1,101)\n",
    "    plt.figure()\n",
    "    plt.plot(x_epoch,loss_train,label='train_loss',marker='+',linewidth=1)\n",
    "    plt.plot(x_epoch,loss_test,label='test_loss',marker='^',linewidth=1)\n",
    "    plt.xlabel('Epoches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    end = time.time()\n",
    "    print(end-start)  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得DAE的数据\n",
    "model_path = 'AE_model.pkl'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "norm_origial = pd.read_csv('data_norm.csv')\n",
    "norm_origial.drop(['I'],axis = 1,inplace=True)\n",
    "\n",
    "data = norm_origial.iloc[:,2:]\n",
    "data_id = norm_origial.iloc[:,:2]\n",
    "label = norm_origial[['LAT','LON']]\n",
    "\n",
    "data_all = data.replace({np.nan:0.0})\n",
    "data_DAE = np.array(data_all)\n",
    "x_data = torch.from_numpy(data_DAE[:,:]).type(torch.float32)\n",
    "hidden_vector_torch,_ = model(x_data)\n",
    "\n",
    "hidden_vector = pd.DataFrame(hidden_vector_torch.detach().numpy(),columns=['h1','h2','h3','h4'])\n",
    "cols = ['SID','TIME','h1','h2','h3','h4','LAT','LON']\n",
    "# print(hidden_vector)\n",
    "\n",
    "hidden_vector_value = np.hstack((data_id.values,hidden_vector))\n",
    "hidden_vector_value = np.hstack((hidden_vector_value,label.values))\n",
    "hidden_vector_data = pd.DataFrame(hidden_vector_value,columns=cols)\n",
    "\n",
    "# print(hidden_vector_data.head())\n",
    "\n",
    "hidden_vector_data.to_csv('hidden_vector_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "# 监督化\n",
    "\n",
    "def series_to_supervised(data,n_in,n_out,Label):\n",
    "#     label : list 标签\n",
    "    col_name = data.columns    \n",
    "    cols,names = list(),list()\n",
    "    # 输入序列\n",
    "    for i in range(n_in,0,-1):\n",
    "        cols.append(data.shift(i))\n",
    "        names += [(x+'(t-%d)')%i for x in col_name]\n",
    "       \n",
    "    # 预测序列 (t,t+1,...,t+n)\n",
    "    for i in range(0,n_out):\n",
    "        for j in Label:\n",
    "            cols.append(data[j].shift(-i))  \n",
    "            names += ['label_'+j+'_(t+%d)'%i]    \n",
    "#     print(names)\n",
    "    data_super = pd.concat(cols,axis = 1)\n",
    "    data_super.columns = names\n",
    "    \n",
    "    return data_super,cols\n",
    "\n",
    "\n",
    "def supervised(data):\n",
    "#     k:总步长\n",
    "    start = 0\n",
    "    data_new = pd.DataFrame()\n",
    "    count = 0\n",
    "    while start < len(data) - 2:\n",
    "        target = start + 1\n",
    "        # start 定死了，target 往后移\n",
    "        while data['SID'][start] == data['SID'][target] and target < len(data) - 1:\n",
    "            target += 1\n",
    "        count += 1\n",
    "#         print('start:%d,end:%d'%(start,target))\n",
    "        data_local, cols = series_to_supervised(data[start:target],16,8,['LAT','LON']) \n",
    "        data_new = data_new.append(data_local,ignore_index=True)\n",
    "        start = target\n",
    "    return data_new,count  \n",
    "\n",
    "data_new,count = supervised(hidden_vector_data)\n",
    "\n",
    "del_features_1 = [['SID(t-'+str(i)+')','TIME(t-'+str(i)+')'] for i in range(16,0,-1)]\n",
    "# del_features_2 = [['SID(t+'+str(i)+')','TIME(t+'+str(i)+')'] for i in range(0,8,1)]\n",
    "\n",
    "for i in del_features_1:\n",
    "    data_new.drop(i,axis = 1,inplace=True)\n",
    "data_new.to_csv('supervised_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq_Atten\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,seq_len,n_features,embedding_dim = 64):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.seq_len,self.n_features = seq_len,n_features\n",
    "        self.embedding_dim,self.hidden_dim = embedding_dim,embedding_dim\n",
    "        self.num_layers = 3\n",
    "        self.rnn1 = nn.LSTM(\n",
    "        input_size = n_features,\n",
    "        hidden_size = self.hidden_dim,\n",
    "        num_layers = 3,\n",
    "        batch_first = True,\n",
    "        dropout = 0.35\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x.reshape((1,self.seq_len,self.n_features))\n",
    "        h_1 = torch.zeros(self.num_layers,x_size(0),self.hidden_dim)\n",
    "        c_1 = torch.zeros(self.num_layers,x.size(0),self.hidden_dim)\n",
    "        x,(hidden,cell) = self.rnn1(x,(h_1,c_1,))\n",
    "        return x,hidden,cell\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,enc_hid_dim,dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear((enc_hid_dim)+dec_hid_dim,dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim,1,bias = False)\n",
    "    def forward(self,hidden,encoder_outputs):\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        hidden = hidden[2:3,:,:]\n",
    "        hidden = hidden.repeat(1,src_len,1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden,encoder_outputs),dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention,dim=1)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,seq_len,input_dim=64,n_features=1):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.seq_len,self.input_dim = seq_len,input_dim\n",
    "        self.hidden_dim,self.n_features = input_dim,n_features\n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=input_dim,\n",
    "            num_layers=3,\n",
    "            batch_first=True,\n",
    "            dropout = 0.35\n",
    "        )\n",
    "        self.output_layer = nn.Linear(self.hidden_dim,n_features)\n",
    "    def forward(self, x,input_hidden,input_cell):       \n",
    "        x = x.reshape((1,1,1))\n",
    "        x, (hidden_n, cell_n) = self.rnn1(x,(input_hidden,input_cell))\n",
    "        x = self.output_layer(x)\n",
    "        return x, hidden_n, cell_n\n",
    "    \n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self,seq_len,attention,input_dim = 64,n_features=1,encoder_hidden_state=512):\n",
    "        super(AttentionDecoder,self).__init__()\n",
    "        self.seq_len, self.input_dim = seq_len, input_dim\n",
    "        self.hidden_dim, self.n_features =  input_dim, n_features\n",
    "        self.attention = attention \n",
    "        self.rnn1 = nn.LSTM(\n",
    "        input_size = encoder_hidden_state,\n",
    "        hidden_size = input_dim,\n",
    "        num_layers = 3,\n",
    "        dropout = 0.35         \n",
    "        )\n",
    "        self.output_layer = nn.Linear(self.hidden_dim * 2 , n_features)\n",
    "    def forward(self, x,input_hidden,input_cell,encoder_outputs):\n",
    "        a = self.attention(input_hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        x = x.reshape((1,1,1))\n",
    "        rnn_input = torch.cat((x, weighted), dim = 2)\n",
    "        x, (hidden_n, cell_n) = self.rnn1(rnn_input,(input_hidden,input_cell))\n",
    "        output = x.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        x = self.output_layer(torch.cat((output, weighted), dim = 1))\n",
    "        return x, hidden_n, cell_n\n",
    "       \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,seq_len,n_features,embedding_dim = 64,output_length = 8):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        self.encoder = Encoder(seq_len,n_features,embedding_dim)\n",
    "        self.attention = Attention(512,512)\n",
    "        self.output_length = output_length\n",
    "        self.decoder = AttentionDecoder(seq_len,self.attention,embedding_dim,n_features)\n",
    "    def forward(self,x,prev_y):\n",
    "        encoder_outputs,hidden,cell = self.encoder(x)\n",
    "        target_ta = []\n",
    "        prev_output = prev_y\n",
    "        for out_days in range(self.output_length):\n",
    "            prev_x,prev_hidden,prev_cell = self.decoder(prev_output,\n",
    "                                                       hidden,cell,encoder_outputs)\n",
    "            hidden,cell = prev_hidden,prev_cell\n",
    "            prev_output = prev_x\n",
    "            target_ta.append(prev_x.reshape(1))\n",
    "        targets = torch.stack(target_ta)\n",
    "        return targets\n",
    "\n",
    "n_features = 40\n",
    "seq_length = 16\n",
    "label_length = 8\n",
    "model = Seq2Seq(seq_length,n_features)\n",
    "model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-2d0ee36dda45>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-2d0ee36dda45>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    optimizer = torch.optim.Adam(model.parameters(),lr=)\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 训练吧，皮卡萍！\n",
    "lr = 4e-3\n",
    "weight_decay = 1e-5\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def init_weights(m):\n",
    "    for name,parm in m.named_parameters():\n",
    "        nn.init.uniform_(param.data,-0.08,0.08)\n",
    "model.apply(init_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
